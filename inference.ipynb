{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":91844,"databundleVersionId":11361821,"sourceType":"competition"},{"sourceId":11870659,"sourceType":"datasetVersion","datasetId":7459867},{"sourceId":676526,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":512947,"modelId":527586}],"dockerImageVersionId":31192,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport gc\nimport warnings\nimport logging\nimport time\nimport math\nimport cv2\nfrom pathlib import Path\nimport numpy as np\nimport pandas as pd\nimport librosa\nimport soundfile as sf\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport timm\nfrom tqdm.auto import tqdm\nfrom glob import glob\nimport random\nimport itertools\nfrom typing import Union\nimport concurrent.futures\n\nwarnings.filterwarnings(\"ignore\")\nlogging.basicConfig(level=logging.ERROR)\n\n# ==========================================\n# 1. Configuration\n# ==========================================\nclass CFG:\n    seed = 42\n    num_workers = 2\n    \n    # 路径设置\n    train_datadir = '/kaggle/input/birdclef-2025/train_audio'\n    train_csv = '/kaggle/input/birdclef-2025/train.csv'\n    test_soundscapes = '/kaggle/input/birdclef-2025/test_soundscapes'\n    submission_csv = '/kaggle/input/birdclef-2025/sample_submission.csv'\n    taxonomy_csv = '/kaggle/input/birdclef-2025/taxonomy.csv'\n    \n    # [关键] 修改这里为你上传的模型路径\n    # 假设你把 best_model.pth 上传到了一个叫 birdclef-my-model 的数据集里\n    model_files = [\n        '/kaggle/input/sed-baseline/pytorch/default/1/best_model.pth' \n    ]\n \n    # 模型参数 (必须与训练时一致)\n    model_name = 'efficientnet_b0'  \n    pretrained = False\n    in_channels = 1\n    \n    # 音频参数 (必须与训练时一致)\n    SR = 32000\n    target_duration = 5 # 5秒切片\n    \n    # MelSpectrogram 参数\n    n_fft = 1024\n    hop_length = 512\n    n_mels = 128\n    f_min = 50\n    f_max = 14000\n    target_shape = (256, 256)\n    \n    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n\ncfg = CFG()\n\nprint(f\"Using device: {cfg.device}\")\nprint(f\"Loading taxonomy data...\")\n# 如果本地没有 taxonomy (比如在测试只有 sample_submission 的时候)，做个兼容\nif os.path.exists(cfg.taxonomy_csv):\n    taxonomy_df = pd.read_csv(cfg.taxonomy_csv)\n    species_ids = taxonomy_df['primary_label'].tolist()\nelse:\n    # Fallback: read from sample_submission\n    ss = pd.read_csv(cfg.submission_csv)\n    species_ids = [c for c in ss.columns if c != 'row_id']\n\nnum_classes = len(species_ids)\nprint(f\"Number of classes: {num_classes}\")\n\n# ==========================================\n# 2. Utilities\n# ==========================================\ndef set_seed(seed=42):\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nset_seed(cfg.seed)\n\n# ==========================================\n# 3. Model Definition (Matching your training)\n# ==========================================\nclass BirdCLEFModel(nn.Module):\n    def __init__(self, cfg):\n        super().__init__()\n        self.cfg = cfg\n        \n        # 骨干网络\n        self.backbone = timm.create_model(\n            cfg.model_name,\n            pretrained=False, # 推理时无法联网，设为 False\n            in_chans=cfg.in_channels\n        )\n\n        # 替换分类头\n        if 'efficientnet' in cfg.model_name:\n            backbone_out = self.backbone.classifier.in_features\n            self.backbone.classifier = nn.Identity()\n        else:\n            backbone_out = self.backbone.num_features\n            self.backbone.reset_classifier(0, '')\n            \n        self.pooling = nn.AdaptiveAvgPool2d(1)\n        \n        # 这里的 num_classes 需要从全局变量或 cfg 获取\n        global num_classes\n        self.classifier = nn.Linear(backbone_out, num_classes)\n\n    def forward(self, x):\n        # x: (batch, 1, freq, time)\n        x = self.backbone(x)\n        \n        # 处理 timm 输出可能的 dict\n        if isinstance(x, dict):\n            x = x['features']\n            \n        # Global Average Pooling\n        if len(x.shape) == 4:\n            x = self.pooling(x)\n            x = x.view(x.size(0), -1)\n            \n        logits = self.classifier(x)\n        return logits\n\n# ==========================================\n# 4. Feature Extraction (Librosa)\n# ==========================================\nclass LogMelFeatureExtractor:\n    def __init__(self, cfg):\n        self.cfg = cfg\n    \n    def __call__(self, audio_data):\n        # audio_data: numpy array (samples,)\n        mel_spec = librosa.feature.melspectrogram(\n            y=audio_data, \n            sr=self.cfg.SR, \n            n_fft=self.cfg.n_fft, \n            hop_length=self.cfg.hop_length, \n            n_mels=self.cfg.n_mels, \n            fmin=self.cfg.f_min, \n            fmax=self.cfg.f_max, \n            power=2.0\n        )\n        # Log Scale\n        mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n        \n        # Min-Max Normalization to [0, 1]\n        mel_spec_norm = (mel_spec_db - mel_spec_db.min()) / (mel_spec_db.max() - mel_spec_db.min() + 1e-8)\n        \n        # Resize to fixed shape (256, 256)\n        if mel_spec_norm.shape != self.cfg.target_shape:\n            mel_spec_norm = cv2.resize(mel_spec_norm, self.cfg.target_shape, interpolation=cv2.INTER_LINEAR)\n            \n        return mel_spec_norm.astype(np.float32)\n\n# ==========================================\n# 5. Audio Loading & Slicing\n# ==========================================\ndef load_and_slice_audio(path, cfg):\n    \"\"\"\n    读取音频并切分为 5秒的片段\n    \"\"\"\n    try:\n        audio, _ = librosa.load(path, sr=cfg.SR)\n    except Exception as e:\n        print(f\"Error loading {path}: {e}\")\n        return [], []\n\n    # 计算需要的切片数\n    chunk_len = int(cfg.target_duration * cfg.SR)\n    # math.ceil 向上取整\n    num_chunks = math.ceil(len(audio) / chunk_len)\n    \n    # 补齐长度\n    target_len = num_chunks * chunk_len\n    if len(audio) < target_len:\n        audio = np.pad(audio, (0, target_len - len(audio)))\n        \n    segments = []\n    end_seconds = []\n    \n    for i in range(num_chunks):\n        seg = audio[i*chunk_len : (i+1)*chunk_len]\n        segments.append(seg)\n        end_seconds.append((i+1) * cfg.target_duration)\n        \n    return segments, end_seconds\n\n# ==========================================\n# 6. Model Loading\n# ==========================================\ndef load_models(cfg):\n    models = []\n    model_files = cfg.model_files\n    \n    if not model_files:\n        print(f\"Warning: No model files found!\")\n        return models\n    \n    print(f\"Found a total of {len(model_files)} model files.\")\n    \n    for model_path in model_files:\n        if not os.path.exists(model_path):\n            print(f\"Path does not exist: {model_path}\")\n            continue\n            \n        try:\n            print(f\"Loading model: {model_path}\")\n            # [关键] weights_only=False 避免 CFG 类报错\n            checkpoint = torch.load(model_path, map_location=torch.device(cfg.device), weights_only=False)\n            \n            # 初始化模型\n            model = BirdCLEFModel(cfg)\n            \n            # 加载权重\n            if 'model_state_dict' in checkpoint:\n                state_dict = checkpoint['model_state_dict']\n            else:\n                state_dict = checkpoint\n            \n            model.load_state_dict(state_dict)\n            model = model.to(cfg.device)\n            model.eval()\n            \n            # 半精度加速 (可选，如果 GPU 支持)\n            # model.half() \n            \n            models.append(model)\n        except Exception as e:\n            print(f\"Error loading model {model_path}: {e}\")\n            import traceback\n            traceback.print_exc()\n    \n    return models\n\n# ==========================================\n# 7. Inference Function (Per File)\n# ==========================================\ndef predict_on_file(audio_path, models, cfg, feature_extractor):\n    \"\"\"\n    处理单个音频文件\n    \"\"\"\n    audio_path = str(audio_path)\n    row_ids = []\n    predictions = []\n    soundscape_id = Path(audio_path).stem.split('.')[0] # 只要文件名部分\n\n    # 1. 加载并切片音频\n    segments, seconds = load_and_slice_audio(audio_path, cfg)\n    \n    if len(segments) == 0:\n        return [], []\n\n    # 2. 预处理 (Feature Extraction)\n    # 批量处理以加速 (但在 CPU 上可能还是串行比较稳妥)\n    batch_imgs = []\n    for seg in segments:\n        spec = feature_extractor(seg) # (256, 256)\n        batch_imgs.append(spec)\n    \n    # 转为 Tensor: (Batch, 1, 256, 256)\n    batch_tensor = torch.tensor(np.array(batch_imgs), dtype=torch.float32).unsqueeze(1).to(cfg.device)\n    \n    # 3. 推理\n    file_preds = []\n    \n    # 这里的 models 是一个列表（哪怕只有一个模型），方便以后做 Ensemble\n    for model in models:\n        with torch.no_grad():\n            # (Batch, Num_Classes)\n            logits = model(batch_tensor)\n            probs = torch.sigmoid(logits).cpu().numpy()\n            file_preds.append(probs)\n    \n    # 如果有多个模型，取平均\n    final_preds = np.mean(file_preds, axis=0) # (Batch, Num_Classes)\n    \n    # 4. 生成 Row IDs\n    for i, sec in enumerate(seconds):\n        row_id = f\"{soundscape_id}_{int(sec)}\"\n        row_ids.append(row_id)\n        predictions.append(final_preds[i])\n        \n    return row_ids, predictions\n\n# ==========================================\n# 8. Main Inference Loop\n# ==========================================\ndef run_inference(cfg, models):\n    # 1. 查找测试文件\n    test_files = sorted(list(Path(cfg.test_soundscapes).glob('*.ogg')))\n    \n    # Commit 阶段如果没有文件，用训练集的前几个充数，或者直接返回\n    if len(test_files) == 0:\n        print(\"No test files found (Commit Stage). Using dummy files if available or skipping.\")\n        # 这里为了防止空报错，通常会生成 dummy submission\n        return [], []\n    \n    print(f\"Found {len(test_files)} test soundscapes\")\n\n    all_row_ids = []\n    all_predictions = []\n    \n    feature_extractor = LogMelFeatureExtractor(cfg)\n\n    # 2. 并行处理\n    # max_workers 根据 CPU 核心数调整，音频处理是 IO 密集型 + CPU 密集型\n    with concurrent.futures.ThreadPoolExecutor(max_workers=cfg.num_workers) as executor:\n        results = list(\n            tqdm(\n                executor.map(\n                    predict_on_file,\n                    test_files,\n                    itertools.repeat(models),\n                    itertools.repeat(cfg),\n                    itertools.repeat(feature_extractor)\n                ),\n                total=len(test_files),\n                desc=\"Inferencing\"\n            )\n        )\n\n    # 3. 汇总结果\n    for rids, preds in results:\n        all_row_ids.extend(rids)\n        all_predictions.extend(preds)\n    \n    return all_row_ids, all_predictions\n\n# ==========================================\n# 9. Submission & Smoothing\n# ==========================================\ndef create_submission(row_ids, predictions, species_ids, cfg):\n    print(\"Creating submission dataframe...\")\n    \n    if len(row_ids) == 0:\n        # Dummy submission creation\n        print(\"Generating dummy submission structure.\")\n        sample_sub = pd.read_csv(cfg.submission_csv)\n        sample_sub.to_csv(\"submission.csv\", index=False)\n        return\n\n    # 构建 DataFrame\n    # predictions 是一个 list of arrays\n    preds_np = np.array(predictions)\n    \n    submission_df = pd.DataFrame(preds_np, columns=species_ids)\n    submission_df.insert(0, 'row_id', row_ids)\n\n    # 对齐列名 (以防万一)\n    if os.path.exists(cfg.submission_csv):\n        sample_sub = pd.read_csv(cfg.submission_csv)\n        # 补全缺失列\n        missing_cols = set(sample_sub.columns) - set(submission_df.columns)\n        for col in missing_cols:\n            submission_df[col] = 0.0\n        # 排序\n        submission_df = submission_df[sample_sub.columns]\n    \n    return submission_df\n\ndef smooth_submission(submission_path):\n    \"\"\"\n    后处理平滑：如果前一秒和后一秒都有鸟叫，中间大概率也是。\n    (0.8 * curr) + (0.2 * neighbor)\n    \"\"\"\n    print(\"Smoothing submission predictions...\")\n    if not os.path.exists(submission_path): return\n\n    sub = pd.read_csv(submission_path)\n    if len(sub) == 0: return\n\n    cols = sub.columns[1:]\n    # 提取 soundscape 文件名作为 group key\n    groups = sub['row_id'].str.rsplit('_', n=1).str[0].values\n    unique_groups = np.unique(groups)\n    \n    for group in unique_groups:\n        idx = np.where(groups == group)[0]\n        # 如果该文件只有一个切片，无法平滑\n        if len(idx) <= 1: continue\n\n        sub_group = sub.iloc[idx].copy()\n        predictions = sub_group[cols].values.astype(float)\n        new_predictions = predictions.copy()\n        \n        # 首尾特殊处理\n        new_predictions[0] = (predictions[0] * 0.8) + (predictions[1] * 0.2)\n        new_predictions[-1] = (predictions[-1] * 0.8) + (predictions[-2] * 0.2)\n        \n        # 中间部分处理\n        # curr * 0.6 + prev * 0.2 + next * 0.2\n        for i in range(1, predictions.shape[0]-1):\n            new_predictions[i] = (predictions[i-1] * 0.2) + (predictions[i] * 0.6) + (predictions[i+1] * 0.2)\n        \n        # 回写\n        sub.iloc[idx, 1:] = new_predictions\n    \n    sub.to_csv(submission_path, index=False)\n    print(f\"Smoothed submission saved to {submission_path}\")\n\n# ==========================================\n# 10. Main Execution\n# ==========================================\ndef main():\n    start_time = time.time()\n    print(\"Starting BirdCLEF-2025 inference...\")\n\n    # 1. 加载模型\n    models = load_models(cfg)\n    \n    if not models:\n        print(\"No models found! Please check model paths.\")\n        # 生成一个空的以防止报错\n        create_submission([], [], species_ids, cfg)\n        return\n    \n    print(f\"Model usage: {'Single model' if len(models) == 1 else f'Ensemble of {len(models)} models'}\")\n\n    # 2. 运行推理\n    row_ids, predictions = run_inference(cfg, models)\n\n    # 3. 生成 CSV\n    submission_df = create_submission(row_ids, predictions, species_ids, cfg)\n    \n    if submission_df is not None:\n        submission_path = 'submission.csv'\n        submission_df.to_csv(submission_path, index=False)\n        print(f\"Submission saved to {submission_path}\")\n\n        # 4. 平滑结果\n        smooth_submission(submission_path)\n    \n    end_time = time.time()\n    print(f\"Inference completed in {(end_time - start_time)/60:.2f} minutes\")\n    \n    # 打印前几行看看\n    if os.path.exists(\"submission.csv\"):\n        print(pd.read_csv(\"submission.csv\").head())\n\nif __name__ == \"__main__\":\n    main()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-08T12:43:38.586968Z","iopub.execute_input":"2025-12-08T12:43:38.587283Z","iopub.status.idle":"2025-12-08T12:43:40.888434Z","shell.execute_reply.started":"2025-12-08T12:43:38.587262Z","shell.execute_reply":"2025-12-08T12:43:40.887406Z"}},"outputs":[{"name":"stdout","text":"Using device: cpu\nLoading taxonomy data...\nNumber of classes: 206\nStarting BirdCLEF-2025 inference...\nFound a total of 1 model files.\nLoading model: /kaggle/input/bird2025-sed-ckpt/sedmodel.pth\nError loading model /kaggle/input/bird2025-sed-ckpt/sedmodel.pth: Error(s) in loading state_dict for BirdCLEFModel:\n\tMissing key(s) in state_dict: \"backbone.conv_stem.weight\", \"backbone.blocks.0.0.conv_dw.weight\", \"backbone.blocks.0.0.bn1.weight\", \"backbone.blocks.0.0.bn1.bias\", \"backbone.blocks.0.0.bn1.running_mean\", \"backbone.blocks.0.0.bn1.running_var\", \"backbone.blocks.0.0.se.conv_reduce.weight\", \"backbone.blocks.0.0.se.conv_reduce.bias\", \"backbone.blocks.0.0.se.conv_expand.weight\", \"backbone.blocks.0.0.se.conv_expand.bias\", \"backbone.blocks.0.0.conv_pw.weight\", \"backbone.blocks.0.0.bn2.weight\", \"backbone.blocks.0.0.bn2.bias\", \"backbone.blocks.0.0.bn2.running_mean\", \"backbone.blocks.0.0.bn2.running_var\", \"backbone.blocks.1.0.conv_pw.weight\", \"backbone.blocks.1.0.bn1.weight\", \"backbone.blocks.1.0.bn1.bias\", \"backbone.blocks.1.0.bn1.running_mean\", \"backbone.blocks.1.0.bn1.running_var\", \"backbone.blocks.1.0.conv_dw.weight\", \"backbone.blocks.1.0.bn2.weight\", \"backbone.blocks.1.0.bn2.bias\", \"backbone.blocks.1.0.bn2.running_mean\", \"backbone.blocks.1.0.bn2.running_var\", \"backbone.blocks.1.0.se.conv_reduce.weight\", \"backbone.blocks.1.0.se.conv_reduce.bias\", \"backbone.blocks.1.0.se.conv_expand.weight\", \"backbone.blocks.1.0.se.conv_expand.bias\", \"backbone.blocks.1.0.conv_pwl.weight\", \"backbone.blocks.1.0.bn3.weight\", \"backbone.blocks.1.0.bn3.bias\", \"backbone.blocks.1.0.bn3.running_mean\", \"backbone.blocks.1.0.bn3.running_var\", \"backbone.blocks.1.1.conv_pw.weight\", \"backbone.blocks.1.1.bn1.weight\", \"backbone.blocks.1.1.bn1.bias\", \"backbone.blocks.1.1.bn1.running_mean\", \"backbone.blocks.1.1.bn1.running_var\", \"backbone.blocks.1.1.conv_dw.weight\", \"backbone.blocks.1.1.bn2.weight\", \"backbone.blocks.1.1.bn2.bias\", \"backbone.blocks.1.1.bn2.running_mean\", \"backbone.blocks.1.1.bn2.running_var\", \"backbone.blocks.1.1.se.conv_reduce.weight\", \"backbone.blocks.1.1.se.conv_reduce.bias\", \"backbone.blocks.1.1.se.conv_expand.weight\", \"backbone.blocks.1.1.se.conv_expand.bias\", \"backbone.blocks.1.1.conv_pwl.weight\", \"backbone.blocks.1.1.bn3.weight\", \"backbone.blocks.1.1.bn3.bias\", \"backbone.blocks.1.1.bn3.running_mean\", \"backbone.blocks.1.1.bn3.running_var\", \"backbone.blocks.2.0.conv_pw.weight\", \"backbone.blocks.2.0.bn1.weight\", \"backbone.blocks.2.0.bn1.bias\", \"backbone.blocks.2.0.bn1.running_mean\", \"backbone.blocks.2.0.bn1.running_var\", \"backbone.blocks.2.0.conv_dw.weight\", \"backbone.blocks.2.0.bn2.weight\", \"backbone.blocks.2.0.bn2.bias\", \"backbone.blocks.2.0.bn2.running_mean\", \"backbone.blocks.2.0.bn2.running_var\", \"backbone.blocks.2.0.se.conv_reduce.weight\", \"backbone.blocks.2.0.se.conv_reduce.bias\", \"backbone.blocks.2.0.se.conv_expand.weight\", \"backbone.blocks.2.0.se.conv_expand.bias\", \"backbone.blocks.2.0.conv_pwl.weight\", \"backbone.blocks.2.0.bn3.weight\", \"backbone.blocks.2.0.bn3.bias\", \"backbone.blocks.2.0.bn3.running_mean\", \"backbone.blocks.2.0.bn3.running_var\", \"backbone.blocks.2.1.conv_pw.weight\", \"backbone.blocks.2.1.bn1.weight\", \"backbone.blocks.2.1.bn1.bias\", \"backbone.blocks.2.1.bn1.running_mean\", \"backbone.blocks.2.1.bn1.running_var\", \"backbone.blocks.2.1.conv_dw.weight\", \"backbone.blocks.2.1.bn2.weight\", \"backbone.blocks.2.1.bn2.bias\", \"backbone.blocks.2.1.bn2.running_mean\", \"backbone.blocks.2.1.bn2.running_var\", \"backbone.blocks.2.1.se.conv_reduce.weight\", \"backbone.blocks.2.1.se.conv_reduce.bias\", \"backbone.blocks.2.1.se.conv_expand.weight\", \"backbone.blocks.2.1.se.conv_expand.bias\", \"backbone.blocks.2.1.conv_pwl.weight\", \"backbone.blocks.2.1.bn3.weight\", \"backbone.blocks.2.1.bn3.bias\", \"backbone.blocks.2.1.bn3.running_mean\", \"backbone.blocks.2.1.bn3.running_var\", \"backbone.blocks.3.0.conv_pw.weight\", \"backbone.blocks.3.0.bn1.weight\", \"backbone.blocks.3.0.bn1.bias\", \"backbone.blocks.3.0.bn1.running_mean\", \"backbone.blocks.3.0.bn1.running_var\", \"backbone.blocks.3.0.conv_dw.weight\", \"backbone.blocks.3.0.bn2.weight\", \"backbone.blocks.3.0.bn2.bias\", \"backbone.blocks.3.0.bn2.running_mean\", \"backbone.blocks.3.0.bn2.running_var\", \"backbone.blocks.3.0.se.conv_reduce.weight\", \"backbone.blocks.3.0.se.conv_reduce.bias\", \"backbone.blocks.3.0.se.conv_expand.weight\", \"backbone.blocks.3.0.se.conv_expand.bias\", \"backbone.blocks.3.0.conv_pwl.weight\", \"backbone.blocks.3.0.bn3.weight\", \"backbone.blocks.3.0.bn3.bias\", \"backbone.blocks.3.0.bn3.running_mean\", \"backbone.blocks.3.0.bn3.running_var\", \"backbone.blocks.3.1.conv_pw.weight\", \"backbone.blocks.3.1.bn1.weight\", \"backbone.blocks.3.1.bn1.bias\", \"backbone.blocks.3.1.bn1.running_mean\", \"backbone.blocks.3.1.bn1.running_var\", \"backbone.blocks.3.1.conv_dw.weight\", \"backbone.blocks.3.1.bn2.weight\", \"backbone.blocks.3.1.bn2.bias\", \"backbone.blocks.3.1.bn2.running_mean\", \"backbone.blocks.3.1.bn2.running_var\", \"backbone.blocks.3.1.se.conv_reduce.weight\", \"backbone.blocks.3.1.se.conv_reduce.bias\", \"backbone.blocks.3.1.se.conv_expand.weight\", \"backbone.blocks.3.1.se.conv_expand.bias\", \"backbone.blocks.3.1.conv_pwl.weight\", \"backbone.blocks.3.1.bn3.weight\", \"backbone.blocks.3.1.bn3.bias\", \"backbone.blocks.3.1.bn3.running_mean\", \"backbone.blocks.3.1.bn3.running_var\", \"backbone.blocks.3.2.conv_pw.weight\", \"backbone.blocks.3.2.bn1.weight\", \"backbone.blocks.3.2.bn1.bias\", \"backbone.blocks.3.2.bn1.running_mean\", \"backbone.blocks.3.2.bn1.running_var\", \"backbone.blocks.3.2.conv_dw.weight\", \"backbone.blocks.3.2.bn2.weight\", \"backbone.blocks.3.2.bn2.bias\", \"backbone.blocks.3.2.bn2.running_mean\", \"backbone.blocks.3.2.bn2.running_var\", \"backbone.blocks.3.2.se.conv_reduce.weight\", \"backbone.blocks.3.2.se.conv_reduce.bias\", \"backbone.blocks.3.2.se.conv_expand.weight\", \"backbone.blocks.3.2.se.conv_expand.bias\", \"backbone.blocks.3.2.conv_pwl.weight\", \"backbone.blocks.3.2.bn3.weight\", \"backbone.blocks.3.2.bn3.bias\", \"backbone.blocks.3.2.bn3.running_mean\", \"backbone.blocks.3.2.bn3.running_var\", \"backbone.blocks.4.0.conv_pw.weight\", \"backbone.blocks.4.0.bn1.weight\", \"backbone.blocks.4.0.bn1.bias\", \"backbone.blocks.4.0.bn1.running_mean\", \"backbone.blocks.4.0.bn1.running_var\", \"backbone.blocks.4.0.conv_dw.weight\", \"backbone.blocks.4.0.bn2.weight\", \"backbone.blocks.4.0.bn2.bias\", \"backbone.blocks.4.0.bn2.running_mean\", \"backbone.blocks.4.0.bn2.running_var\", \"backbone.blocks.4.0.se.conv_reduce.weight\", \"backbone.blocks.4.0.se.conv_reduce.bias\", \"backbone.blocks.4.0.se.conv_expand.weight\", \"backbone.blocks.4.0.se.conv_expand.bias\", \"backbone.blocks.4.0.conv_pwl.weight\", \"backbone.blocks.4.0.bn3.weight\", \"backbone.blocks.4.0.bn3.bias\", \"backbone.blocks.4.0.bn3.running_mean\", \"backbone.blocks.4.0.bn3.running_var\", \"backbone.blocks.4.1.conv_pw.weight\", \"backbone.blocks.4.1.bn1.weight\", \"backbone.blocks.4.1.bn1.bias\", \"backbone.blocks.4.1.bn1.running_mean\", \"backbone.blocks.4.1.bn1.running_var\", \"backbone.blocks.4.1.conv_dw.weight\", \"backbone.blocks.4.1.bn2.weight\", \"backbone.blocks.4.1.bn2.bias\", \"backbone.blocks.4.1.bn2.running_mean\", \"backbone.blocks.4.1.bn2.running_var\", \"backbone.blocks.4.1.se.conv_reduce.weight\", \"backbone.blocks.4.1.se.conv_reduce.bias\", \"backbone.blocks.4.1.se.conv_expand.weight\", \"backbone.blocks.4.1.se.conv_expand.bias\", \"backbone.blocks.4.1.conv_pwl.weight\", \"backbone.blocks.4.1.bn3.weight\", \"backbone.blocks.4.1.bn3.bias\", \"backbone.blocks.4.1.bn3.running_mean\", \"backbone.blocks.4.1.bn3.running_var\", \"backbone.blocks.4.2.conv_pw.weight\", \"backbone.blocks.4.2.bn1.weight\", \"backbone.blocks.4.2.bn1.bias\", \"backbone.blocks.4.2.bn1.running_mean\", \"backbone.blocks.4.2.bn1.running_var\", \"backbone.blocks.4.2.conv_dw.weight\", \"backbone.blocks.4.2.bn2.weight\", \"backbone.blocks.4.2.bn2.bias\", \"backbone.blocks.4.2.bn2.running_mean\", \"backbone.blocks.4.2.bn2.running_var\", \"backbone.blocks.4.2.se.conv_reduce.weight\", \"backbone.blocks.4.2.se.conv_reduce.bias\", \"backbone.blocks.4.2.se.conv_expand.weight\", \"backbone.blocks.4.2.se.conv_expand.bias\", \"backbone.blocks.4.2.conv_pwl.weight\", \"backbone.blocks.4.2.bn3.weight\", \"backbone.blocks.4.2.bn3.bias\", \"backbone.blocks.4.2.bn3.running_mean\", \"backbone.blocks.4.2.bn3.running_var\", \"backbone.blocks.5.0.conv_pw.weight\", \"backbone.blocks.5.0.bn1.weight\", \"backbone.blocks.5.0.bn1.bias\", \"backbone.blocks.5.0.bn1.running_mean\", \"backbone.blocks.5.0.bn1.running_var\", \"backbone.blocks.5.0.conv_dw.weight\", \"backbone.blocks.5.0.bn2.weight\", \"backbone.blocks.5.0.bn2.bias\", \"backbone.blocks.5.0.bn2.running_mean\", \"backbone.blocks.5.0.bn2.running_var\", \"backbone.blocks.5.0.se.conv_reduce.weight\", \"backbone.blocks.5.0.se.conv_reduce.bias\", \"backbone.blocks.5.0.se.conv_expand.weight\", \"backbone.blocks.5.0.se.conv_expand.bias\", \"backbone.blocks.5.0.conv_pwl.weight\", \"backbone.blocks.5.0.bn3.weight\", \"backbone.blocks.5.0.bn3.bias\", \"backbone.blocks.5.0.bn3.running_mean\", \"backbone.blocks.5.0.bn3.running_var\", \"backbone.blocks.5.1.conv_pw.weight\", \"backbone.blocks.5.1.bn1.weight\", \"backbone.blocks.5.1.bn1.bias\", \"backbone.blocks.5.1.bn1.running_mean\", \"backbone.blocks.5.1.bn1.running_var\", \"backbone.blocks.5.1.conv_dw.weight\", \"backbone.blocks.5.1.bn2.weight\", \"backbone.blocks.5.1.bn2.bias\", \"backbone.blocks.5.1.bn2.running_mean\", \"backbone.blocks.5.1.bn2.running_var\", \"backbone.blocks.5.1.se.conv_reduce.weight\", \"backbone.blocks.5.1.se.conv_reduce.bias\", \"backbone.blocks.5.1.se.conv_expand.weight\", \"backbone.blocks.5.1.se.conv_expand.bias\", \"backbone.blocks.5.1.conv_pwl.weight\", \"backbone.blocks.5.1.bn3.weight\", \"backbone.blocks.5.1.bn3.bias\", \"backbone.blocks.5.1.bn3.running_mean\", \"backbone.blocks.5.1.bn3.running_var\", \"backbone.blocks.5.2.conv_pw.weight\", \"backbone.blocks.5.2.bn1.weight\", \"backbone.blocks.5.2.bn1.bias\", \"backbone.blocks.5.2.bn1.running_mean\", \"backbone.blocks.5.2.bn1.running_var\", \"backbone.blocks.5.2.conv_dw.weight\", \"backbone.blocks.5.2.bn2.weight\", \"backbone.blocks.5.2.bn2.bias\", \"backbone.blocks.5.2.bn2.running_mean\", \"backbone.blocks.5.2.bn2.running_var\", \"backbone.blocks.5.2.se.conv_reduce.weight\", \"backbone.blocks.5.2.se.conv_reduce.bias\", \"backbone.blocks.5.2.se.conv_expand.weight\", \"backbone.blocks.5.2.se.conv_expand.bias\", \"backbone.blocks.5.2.conv_pwl.weight\", \"backbone.blocks.5.2.bn3.weight\", \"backbone.blocks.5.2.bn3.bias\", \"backbone.blocks.5.2.bn3.running_mean\", \"backbone.blocks.5.2.bn3.running_var\", \"backbone.blocks.5.3.conv_pw.weight\", \"backbone.blocks.5.3.bn1.weight\", \"backbone.blocks.5.3.bn1.bias\", \"backbone.blocks.5.3.bn1.running_mean\", \"backbone.blocks.5.3.bn1.running_var\", \"backbone.blocks.5.3.conv_dw.weight\", \"backbone.blocks.5.3.bn2.weight\", \"backbone.blocks.5.3.bn2.bias\", \"backbone.blocks.5.3.bn2.running_mean\", \"backbone.blocks.5.3.bn2.running_var\", \"backbone.blocks.5.3.se.conv_reduce.weight\", \"backbone.blocks.5.3.se.conv_reduce.bias\", \"backbone.blocks.5.3.se.conv_expand.weight\", \"backbone.blocks.5.3.se.conv_expand.bias\", \"backbone.blocks.5.3.conv_pwl.weight\", \"backbone.blocks.5.3.bn3.weight\", \"backbone.blocks.5.3.bn3.bias\", \"backbone.blocks.5.3.bn3.running_mean\", \"backbone.blocks.5.3.bn3.running_var\", \"backbone.blocks.6.0.conv_pw.weight\", \"backbone.blocks.6.0.bn1.weight\", \"backbone.blocks.6.0.bn1.bias\", \"backbone.blocks.6.0.bn1.running_mean\", \"backbone.blocks.6.0.bn1.running_var\", \"backbone.blocks.6.0.conv_dw.weight\", \"backbone.blocks.6.0.bn2.weight\", \"backbone.blocks.6.0.bn2.bias\", \"backbone.blocks.6.0.bn2.running_mean\", \"backbone.blocks.6.0.bn2.running_var\", \"backbone.blocks.6.0.se.conv_reduce.weight\", \"backbone.blocks.6.0.se.conv_reduce.bias\", \"backbone.blocks.6.0.se.conv_expand.weight\", \"backbone.blocks.6.0.se.conv_expand.bias\", \"backbone.blocks.6.0.conv_pwl.weight\", \"backbone.blocks.6.0.bn3.weight\", \"backbone.blocks.6.0.bn3.bias\", \"backbone.blocks.6.0.bn3.running_mean\", \"backbone.blocks.6.0.bn3.running_var\", \"backbone.conv_head.weight\", \"backbone.bn2.weight\", \"backbone.bn2.bias\", \"backbone.bn2.running_mean\", \"backbone.bn2.running_var\", \"classifier.weight\", \"classifier.bias\". \n\tUnexpected key(s) in state_dict: \"bn0.weight\", \"bn0.bias\", \"bn0.running_mean\", \"bn0.running_var\", \"bn0.num_batches_tracked\", \"encoder.0.0.weight\", \"encoder.0.1.weight\", \"encoder.0.1.bias\", \"encoder.0.1.running_mean\", \"encoder.0.1.running_var\", \"encoder.0.1.num_batches_tracked\", \"encoder.0.3.weight\", \"encoder.0.4.weight\", \"encoder.0.4.bias\", \"encoder.0.4.running_mean\", \"encoder.0.4.running_var\", \"encoder.0.4.num_batches_tracked\", \"encoder.0.6.weight\", \"encoder.1.weight\", \"encoder.1.bias\", \"encoder.1.running_mean\", \"encoder.1.running_var\", \"encoder.1.num_batches_tracked\", \"encoder.4.0.conv1.weight\", \"encoder.4.0.bn1.weight\", \"encoder.4.0.bn1.bias\", \"encoder.4.0.bn1.running_mean\", \"encoder.4.0.bn1.running_var\", \"encoder.4.0.bn1.num_batches_tracked\", \"encoder.4.0.conv2.weight\", \"encoder.4.0.bn2.weight\", \"encoder.4.0.bn2.bias\", \"encoder.4.0.bn2.running_mean\", \"encoder.4.0.bn2.running_var\", \"encoder.4.0.bn2.num_batches_tracked\", \"encoder.4.0.conv3.weight\", \"encoder.4.0.bn3.weight\", \"encoder.4.0.bn3.bias\", \"encoder.4.0.bn3.running_mean\", \"encoder.4.0.bn3.running_var\", \"encoder.4.0.bn3.num_batches_tracked\", \"encoder.4.0.se.fc1.weight\", \"encoder.4.0.se.fc1.bias\", \"encoder.4.0.se.fc2.weight\", \"encoder.4.0.se.fc2.bias\", \"encoder.4.0.downsample.1.weight\", \"encoder.4.0.downsample.2.weight\", \"encoder.4.0.downsample.2.bias\", \"encoder.4.0.downsample.2.running_mean\", \"encoder.4.0.downsample.2.running_var\", \"encoder.4.0.downsample.2.num_batches_tracked\", \"encoder.4.1.conv1.weight\", \"encoder.4.1.bn1.weight\", \"encoder.4.1.bn1.bias\", \"encoder.4.1.bn1.running_mean\", \"encoder.4.1.bn1.running_var\", \"encoder.4.1.bn1.num_batches_tracked\", \"encoder.4.1.conv2.weight\", \"encoder.4.1.bn2.weight\", \"encoder.4.1.bn2.bias\", \"encoder.4.1.bn2.running_mean\", \"encoder.4.1.bn2.running_var\", \"encoder.4.1.bn2.num_batches_tracked\", \"encoder.4.1.conv3.weight\", \"encoder.4.1.bn3.weight\", \"encoder.4.1.bn3.bias\", \"encoder.4.1.bn3.running_mean\", \"encoder.4.1.bn3.running_var\", \"encoder.4.1.bn3.num_batches_tracked\", \"encoder.4.1.se.fc1.weight\", \"encoder.4.1.se.fc1.bias\", \"encoder.4.1.se.fc2.weight\", \"encoder.4.1.se.fc2.bias\", \"encoder.5.0.conv1.weight\", \"encoder.5.0.bn1.weight\", \"encoder.5.0.bn1.bias\", \"encoder.5.0.bn1.running_mean\", \"encoder.5.0.bn1.running_var\", \"encoder.5.0.bn1.num_batches_tracked\", \"encoder.5.0.conv2.weight\", \"encoder.5.0.bn2.weight\", \"encoder.5.0.bn2.bias\", \"encoder.5.0.bn2.running_mean\", \"encoder.5.0.bn2.running_var\", \"encoder.5.0.bn2.num_batches_tracked\", \"encoder.5.0.conv3.weight\", \"encoder.5.0.bn3.weight\", \"encoder.5.0.bn3.bias\", \"encoder.5.0.bn3.running_mean\", \"encoder.5.0.bn3.running_var\", \"encoder.5.0.bn3.num_batches_tracked\", \"encoder.5.0.se.fc1.weight\", \"encoder.5.0.se.fc1.bias\", \"encoder.5.0.se.fc2.weight\", \"encoder.5.0.se.fc2.bias\", \"encoder.5.0.downsample.1.weight\", \"encoder.5.0.downsample.2.weight\", \"encoder.5.0.downsample.2.bias\", \"encoder.5.0.downsample.2.running_mean\", \"encoder.5.0.downsample.2.running_var\", \"encoder.5.0.downsample.2.num_batches_tracked\", \"encoder.5.1.conv1.weight\", \"encoder.5.1.bn1.weight\", \"encoder.5.1.bn1.bias\", \"encoder.5.1.bn1.running_mean\", \"encoder.5.1.bn1.running_var\", \"encoder.5.1.bn1.num_batches_tracked\", \"encoder.5.1.conv2.weight\", \"encoder.5.1.bn2.weight\", \"encoder.5.1.bn2.bias\", \"encoder.5.1.bn2.running_mean\", \"encoder.5.1.bn2.running_var\", \"encoder.5.1.bn2.num_batches_tracked\", \"encoder.5.1.conv3.weight\", \"encoder.5.1.bn3.weight\", \"encoder.5.1.bn3.bias\", \"encoder.5.1.bn3.running_mean\", \"encoder.5.1.bn3.running_var\", \"encoder.5.1.bn3.num_batches_tracked\", \"encoder.5.1.se.fc1.weight\", \"encoder.5.1.se.fc1.bias\", \"encoder.5.1.se.fc2.weight\", \"encoder.5.1.se.fc2.bias\", \"encoder.6.0.conv1.weight\", \"encoder.6.0.bn1.weight\", \"encoder.6.0.bn1.bias\", \"encoder.6.0.bn1.running_mean\", \"encoder.6.0.bn1.running_var\", \"encoder.6.0.bn1.num_batches_tracked\", \"encoder.6.0.conv2.weight\", \"encoder.6.0.bn2.weight\", \"encoder.6.0.bn2.bias\", \"encoder.6.0.bn2.running_mean\", \"encoder.6.0.bn2.running_var\", \"encoder.6.0.bn2.num_batches_tracked\", \"encoder.6.0.conv3.weight\", \"encoder.6.0.bn3.weight\", \"encoder.6.0.bn3.bias\", \"encoder.6.0.bn3.running_mean\", \"encoder.6.0.bn3.running_var\", \"encoder.6.0.bn3.num_batches_tracked\", \"encoder.6.0.se.fc1.weight\", \"encoder.6.0.se.fc1.bias\", \"encoder.6.0.se.fc2.weight\", \"encoder.6.0.se.fc2.bias\", \"encoder.6.0.downsample.1.weight\", \"encoder.6.0.downsample.2.weight\", \"encoder.6.0.downsample.2.bias\", \"encoder.6.0.downsample.2.running_mean\", \"encoder.6.0.downsample.2.running_var\", \"encoder.6.0.downsample.2.num_batches_tracked\", \"encoder.6.1.conv1.weight\", \"encoder.6.1.bn1.weight\", \"encoder.6.1.bn1.bias\", \"encoder.6.1.bn1.running_mean\", \"encoder.6.1.bn1.running_var\", \"encoder.6.1.bn1.num_batches_tracked\", \"encoder.6.1.conv2.weight\", \"encoder.6.1.bn2.weight\", \"encoder.6.1.bn2.bias\", \"encoder.6.1.bn2.running_mean\", \"encoder.6.1.bn2.running_var\", \"encoder.6.1.bn2.num_batches_tracked\", \"encoder.6.1.conv3.weight\", \"encoder.6.1.bn3.weight\", \"encoder.6.1.bn3.bias\", \"encoder.6.1.bn3.running_mean\", \"encoder.6.1.bn3.running_var\", \"encoder.6.1.bn3.num_batches_tracked\", \"encoder.6.1.se.fc1.weight\", \"encoder.6.1.se.fc1.bias\", \"encoder.6.1.se.fc2.weight\", \"encoder.6.1.se.fc2.bias\", \"encoder.7.0.conv1.weight\", \"encoder.7.0.bn1.weight\", \"encoder.7.0.bn1.bias\", \"encoder.7.0.bn1.running_mean\", \"encoder.7.0.bn1.running_var\", \"encoder.7.0.bn1.num_batches_tracked\", \"encoder.7.0.conv2.weight\", \"encoder.7.0.bn2.weight\", \"encoder.7.0.bn2.bias\", \"encoder.7.0.bn2.running_mean\", \"encoder.7.0.bn2.running_var\", \"encoder.7.0.bn2.num_batches_tracked\", \"encoder.7.0.conv3.weight\", \"encoder.7.0.bn3.weight\", \"encoder.7.0.bn3.bias\", \"encoder.7.0.bn3.running_mean\", \"encoder.7.0.bn3.running_var\", \"encoder.7.0.bn3.num_batches_tracked\", \"encoder.7.0.se.fc1.weight\", \"encoder.7.0.se.fc1.bias\", \"encoder.7.0.se.fc2.weight\", \"encoder.7.0.se.fc2.bias\", \"encoder.7.0.downsample.1.weight\", \"encoder.7.0.downsample.2.weight\", \"encoder.7.0.downsample.2.bias\", \"encoder.7.0.downsample.2.running_mean\", \"encoder.7.0.downsample.2.running_var\", \"encoder.7.0.downsample.2.num_batches_tracked\", \"encoder.7.1.conv1.weight\", \"encoder.7.1.bn1.weight\", \"encoder.7.1.bn1.bias\", \"encoder.7.1.bn1.running_mean\", \"encoder.7.1.bn1.running_var\", \"encoder.7.1.bn1.num_batches_tracked\", \"encoder.7.1.conv2.weight\", \"encoder.7.1.bn2.weight\", \"encoder.7.1.bn2.bias\", \"encoder.7.1.bn2.running_mean\", \"encoder.7.1.bn2.running_var\", \"encoder.7.1.bn2.num_batches_tracked\", \"encoder.7.1.conv3.weight\", \"encoder.7.1.bn3.weight\", \"encoder.7.1.bn3.bias\", \"encoder.7.1.bn3.running_mean\", \"encoder.7.1.bn3.running_var\", \"encoder.7.1.bn3.num_batches_tracked\", \"encoder.7.1.se.fc1.weight\", \"encoder.7.1.se.fc1.bias\", \"encoder.7.1.se.fc2.weight\", \"encoder.7.1.se.fc2.bias\", \"fc1.weight\", \"fc1.bias\", \"att_block.att.weight\", \"att_block.att.bias\", \"att_block.cla.weight\", \"att_block.cla.bias\", \"melspec_transform.spectrogram.window\", \"melspec_transform.mel_scale.fb\", \"backbone.conv1.0.weight\", \"backbone.conv1.1.weight\", \"backbone.conv1.1.bias\", \"backbone.conv1.1.running_mean\", \"backbone.conv1.1.running_var\", \"backbone.conv1.1.num_batches_tracked\", \"backbone.conv1.3.weight\", \"backbone.conv1.4.weight\", \"backbone.conv1.4.bias\", \"backbone.conv1.4.running_mean\", \"backbone.conv1.4.running_var\", \"backbone.conv1.4.num_batches_tracked\", \"backbone.conv1.6.weight\", \"backbone.layer1.0.conv1.weight\", \"backbone.layer1.0.bn1.weight\", \"backbone.layer1.0.bn1.bias\", \"backbone.layer1.0.bn1.running_mean\", \"backbone.layer1.0.bn1.running_var\", \"backbone.layer1.0.bn1.num_batches_tracked\", \"backbone.layer1.0.conv2.weight\", \"backbone.layer1.0.bn2.weight\", \"backbone.layer1.0.bn2.bias\", \"backbone.layer1.0.bn2.running_mean\", \"backbone.layer1.0.bn2.running_var\", \"backbone.layer1.0.bn2.num_batches_tracked\", \"backbone.layer1.0.conv3.weight\", \"backbone.layer1.0.bn3.weight\", \"backbone.layer1.0.bn3.bias\", \"backbone.layer1.0.bn3.running_mean\", \"backbone.layer1.0.bn3.running_var\", \"backbone.layer1.0.bn3.num_batches_tracked\", \"backbone.layer1.0.se.fc1.weight\", \"backbone.layer1.0.se.fc1.bias\", \"backbone.layer1.0.se.fc2.weight\", \"backbone.layer1.0.se.fc2.bias\", \"backbone.layer1.0.downsample.1.weight\", \"backbone.layer1.0.downsample.2.weight\", \"backbone.layer1.0.downsample.2.bias\", \"backbone.layer1.0.downsample.2.running_mean\", \"backbone.layer1.0.downsample.2.running_var\", \"backbone.layer1.0.downsample.2.num_batches_tracked\", \"backbone.layer1.1.conv1.weight\", \"backbone.layer1.1.bn1.weight\", \"backbone.layer1.1.bn1.bias\", \"backbone.layer1.1.bn1.running_mean\", \"backbone.layer1.1.bn1.running_var\", \"backbone.layer1.1.bn1.num_batches_tracked\", \"backbone.layer1.1.conv2.weight\", \"backbone.layer1.1.bn2.weight\", \"backbone.layer1.1.bn2.bias\", \"backbone.layer1.1.bn2.running_mean\", \"backbone.layer1.1.bn2.running_var\", \"backbone.layer1.1.bn2.num_batches_tracked\", \"backbone.layer1.1.conv3.weight\", \"backbone.layer1.1.bn3.weight\", \"backbone.layer1.1.bn3.bias\", \"backbone.layer1.1.bn3.running_mean\", \"backbone.layer1.1.bn3.running_var\", \"backbone.layer1.1.bn3.num_batches_tracked\", \"backbone.layer1.1.se.fc1.weight\", \"backbone.layer1.1.se.fc1.bias\", \"backbone.layer1.1.se.fc2.weight\", \"backbone.layer1.1.se.fc2.bias\", \"backbone.layer2.0.conv1.weight\", \"backbone.layer2.0.bn1.weight\", \"backbone.layer2.0.bn1.bias\", \"backbone.layer2.0.bn1.running_mean\", \"backbone.layer2.0.bn1.running_var\", \"backbone.layer2.0.bn1.num_batches_tracked\", \"backbone.layer2.0.conv2.weight\", \"backbone.layer2.0.bn2.weight\", \"backbone.layer2.0.bn2.bias\", \"backbone.layer2.0.bn2.running_mean\", \"backbone.layer2.0.bn2.running_var\", \"backbone.layer2.0.bn2.num_batches_tracked\", \"backbone.layer2.0.conv3.weight\", \"backbone.layer2.0.bn3.weight\", \"backbone.layer2.0.bn3.bias\", \"backbone.layer2.0.bn3.running_mean\", \"backbone.layer2.0.bn3.running_var\", \"backbone.layer2.0.bn3.num_batches_tracked\", \"backbone.layer2.0.se.fc1.weight\", \"backbone.layer2.0.se.fc1.bias\", \"backbone.layer2.0.se.fc2.weight\", \"backbone.layer2.0.se.fc2.bias\", \"backbone.layer2.0.downsample.1.weight\", \"backbone.layer2.0.downsample.2.weight\", \"backbone.layer2.0.downsample.2.bias\", \"backbone.layer2.0.downsample.2.running_mean\", \"backbone.layer2.0.downsample.2.running_var\", \"backbone.layer2.0.downsample.2.num_batches_tracked\", \"backbone.layer2.1.conv1.weight\", \"backbone.layer2.1.bn1.weight\", \"backbone.layer2.1.bn1.bias\", \"backbone.layer2.1.bn1.running_mean\", \"backbone.layer2.1.bn1.running_var\", \"backbone.layer2.1.bn1.num_batches_tracked\", \"backbone.layer2.1.conv2.weight\", \"backbone.layer2.1.bn2.weight\", \"backbone.layer2.1.bn2.bias\", \"backbone.layer2.1.bn2.running_mean\", \"backbone.layer2.1.bn2.running_var\", \"backbone.layer2.1.bn2.num_batches_tracked\", \"backbone.layer2.1.conv3.weight\", \"backbone.layer2.1.bn3.weight\", \"backbone.layer2.1.bn3.bias\", \"backbone.layer2.1.bn3.running_mean\", \"backbone.layer2.1.bn3.running_var\", \"backbone.layer2.1.bn3.num_batches_tracked\", \"backbone.layer2.1.se.fc1.weight\", \"backbone.layer2.1.se.fc1.bias\", \"backbone.layer2.1.se.fc2.weight\", \"backbone.layer2.1.se.fc2.bias\", \"backbone.layer3.0.conv1.weight\", \"backbone.layer3.0.bn1.weight\", \"backbone.layer3.0.bn1.bias\", \"backbone.layer3.0.bn1.running_mean\", \"backbone.layer3.0.bn1.running_var\", \"backbone.layer3.0.bn1.num_batches_tracked\", \"backbone.layer3.0.conv2.weight\", \"backbone.layer3.0.bn2.weight\", \"backbone.layer3.0.bn2.bias\", \"backbone.layer3.0.bn2.running_mean\", \"backbone.layer3.0.bn2.running_var\", \"backbone.layer3.0.bn2.num_batches_tracked\", \"backbone.layer3.0.conv3.weight\", \"backbone.layer3.0.bn3.weight\", \"backbone.layer3.0.bn3.bias\", \"backbone.layer3.0.bn3.running_mean\", \"backbone.layer3.0.bn3.running_var\", \"backbone.layer3.0.bn3.num_batches_tracked\", \"backbone.layer3.0.se.fc1.weight\", \"backbone.layer3.0.se.fc1.bias\", \"backbone.layer3.0.se.fc2.weight\", \"backbone.layer3.0.se.fc2.bias\", \"backbone.layer3.0.downsample.1.weight\", \"backbone.layer3.0.downsample.2.weight\", \"backbone.layer3.0.downsample.2.bias\", \"backbone.layer3.0.downsample.2.running_mean\", \"backbone.layer3.0.downsample.2.running_var\", \"backbone.layer3.0.downsample.2.num_batches_tracked\", \"backbone.layer3.1.conv1.weight\", \"backbone.layer3.1.bn1.weight\", \"backbone.layer3.1.bn1.bias\", \"backbone.layer3.1.bn1.running_mean\", \"backbone.layer3.1.bn1.running_var\", \"backbone.layer3.1.bn1.num_batches_tracked\", \"backbone.layer3.1.conv2.weight\", \"backbone.layer3.1.bn2.weight\", \"backbone.layer3.1.bn2.bias\", \"backbone.layer3.1.bn2.running_mean\", \"backbone.layer3.1.bn2.running_var\", \"backbone.layer3.1.bn2.num_batches_tracked\", \"backbone.layer3.1.conv3.weight\", \"backbone.layer3.1.bn3.weight\", \"backbone.layer3.1.bn3.bias\", \"backbone.layer3.1.bn3.running_mean\", \"backbone.layer3.1.bn3.running_var\", \"backbone.layer3.1.bn3.num_batches_tracked\", \"backbone.layer3.1.se.fc1.weight\", \"backbone.layer3.1.se.fc1.bias\", \"backbone.layer3.1.se.fc2.weight\", \"backbone.layer3.1.se.fc2.bias\", \"backbone.layer4.0.conv1.weight\", \"backbone.layer4.0.bn1.weight\", \"backbone.layer4.0.bn1.bias\", \"backbone.layer4.0.bn1.running_mean\", \"backbone.layer4.0.bn1.running_var\", \"backbone.layer4.0.bn1.num_batches_tracked\", \"backbone.layer4.0.conv2.weight\", \"backbone.layer4.0.bn2.weight\", \"backbone.layer4.0.bn2.bias\", \"backbone.layer4.0.bn2.running_mean\", \"backbone.layer4.0.bn2.running_var\", \"backbone.layer4.0.bn2.num_batches_tracked\", \"backbone.layer4.0.conv3.weight\", \"backbone.layer4.0.bn3.weight\", \"backbone.layer4.0.bn3.bias\", \"backbone.layer4.0.bn3.running_mean\", \"backbone.layer4.0.bn3.running_var\", \"backbone.layer4.0.bn3.num_batches_tracked\", \"backbone.layer4.0.se.fc1.weight\", \"backbone.layer4.0.se.fc1.bias\", \"backbone.layer4.0.se.fc2.weight\", \"backbone.layer4.0.se.fc2.bias\", \"backbone.layer4.0.downsample.1.weight\", \"backbone.layer4.0.downsample.2.weight\", \"backbone.layer4.0.downsample.2.bias\", \"backbone.layer4.0.downsample.2.running_mean\", \"backbone.layer4.0.downsample.2.running_var\", \"backbone.layer4.0.downsample.2.num_batches_tracked\", \"backbone.layer4.1.conv1.weight\", \"backbone.layer4.1.bn1.weight\", \"backbone.layer4.1.bn1.bias\", \"backbone.layer4.1.bn1.running_mean\", \"backbone.layer4.1.bn1.running_var\", \"backbone.layer4.1.bn1.num_batches_tracked\", \"backbone.layer4.1.conv2.weight\", \"backbone.layer4.1.bn2.weight\", \"backbone.layer4.1.bn2.bias\", \"backbone.layer4.1.bn2.running_mean\", \"backbone.layer4.1.bn2.running_var\", \"backbone.layer4.1.bn2.num_batches_tracked\", \"backbone.layer4.1.conv3.weight\", \"backbone.layer4.1.bn3.weight\", \"backbone.layer4.1.bn3.bias\", \"backbone.layer4.1.bn3.running_mean\", \"backbone.layer4.1.bn3.running_var\", \"backbone.layer4.1.bn3.num_batches_tracked\", \"backbone.layer4.1.se.fc1.weight\", \"backbone.layer4.1.se.fc1.bias\", \"backbone.layer4.1.se.fc2.weight\", \"backbone.layer4.1.se.fc2.bias\", \"backbone.fc.weight\", \"backbone.fc.bias\". \n\tsize mismatch for backbone.bn1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for backbone.bn1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for backbone.bn1.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for backbone.bn1.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\nNo models found! Please check model paths.\nCreating submission dataframe...\nGenerating dummy submission structure.\n","output_type":"stream"},{"name":"stderr","text":"Traceback (most recent call last):\n  File \"/tmp/ipykernel_48/2018984968.py\", line 237, in load_models\n    model.load_state_dict(state_dict)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 2581, in load_state_dict\n    raise RuntimeError(\nRuntimeError: Error(s) in loading state_dict for BirdCLEFModel:\n\tMissing key(s) in state_dict: \"backbone.conv_stem.weight\", \"backbone.blocks.0.0.conv_dw.weight\", \"backbone.blocks.0.0.bn1.weight\", \"backbone.blocks.0.0.bn1.bias\", \"backbone.blocks.0.0.bn1.running_mean\", \"backbone.blocks.0.0.bn1.running_var\", \"backbone.blocks.0.0.se.conv_reduce.weight\", \"backbone.blocks.0.0.se.conv_reduce.bias\", \"backbone.blocks.0.0.se.conv_expand.weight\", \"backbone.blocks.0.0.se.conv_expand.bias\", \"backbone.blocks.0.0.conv_pw.weight\", \"backbone.blocks.0.0.bn2.weight\", \"backbone.blocks.0.0.bn2.bias\", \"backbone.blocks.0.0.bn2.running_mean\", \"backbone.blocks.0.0.bn2.running_var\", \"backbone.blocks.1.0.conv_pw.weight\", \"backbone.blocks.1.0.bn1.weight\", \"backbone.blocks.1.0.bn1.bias\", \"backbone.blocks.1.0.bn1.running_mean\", \"backbone.blocks.1.0.bn1.running_var\", \"backbone.blocks.1.0.conv_dw.weight\", \"backbone.blocks.1.0.bn2.weight\", \"backbone.blocks.1.0.bn2.bias\", \"backbone.blocks.1.0.bn2.running_mean\", \"backbone.blocks.1.0.bn2.running_var\", \"backbone.blocks.1.0.se.conv_reduce.weight\", \"backbone.blocks.1.0.se.conv_reduce.bias\", \"backbone.blocks.1.0.se.conv_expand.weight\", \"backbone.blocks.1.0.se.conv_expand.bias\", \"backbone.blocks.1.0.conv_pwl.weight\", \"backbone.blocks.1.0.bn3.weight\", \"backbone.blocks.1.0.bn3.bias\", \"backbone.blocks.1.0.bn3.running_mean\", \"backbone.blocks.1.0.bn3.running_var\", \"backbone.blocks.1.1.conv_pw.weight\", \"backbone.blocks.1.1.bn1.weight\", \"backbone.blocks.1.1.bn1.bias\", \"backbone.blocks.1.1.bn1.running_mean\", \"backbone.blocks.1.1.bn1.running_var\", \"backbone.blocks.1.1.conv_dw.weight\", \"backbone.blocks.1.1.bn2.weight\", \"backbone.blocks.1.1.bn2.bias\", \"backbone.blocks.1.1.bn2.running_mean\", \"backbone.blocks.1.1.bn2.running_var\", \"backbone.blocks.1.1.se.conv_reduce.weight\", \"backbone.blocks.1.1.se.conv_reduce.bias\", \"backbone.blocks.1.1.se.conv_expand.weight\", \"backbone.blocks.1.1.se.conv_expand.bias\", \"backbone.blocks.1.1.conv_pwl.weight\", \"backbone.blocks.1.1.bn3.weight\", \"backbone.blocks.1.1.bn3.bias\", \"backbone.blocks.1.1.bn3.running_mean\", \"backbone.blocks.1.1.bn3.running_var\", \"backbone.blocks.2.0.conv_pw.weight\", \"backbone.blocks.2.0.bn1.weight\", \"backbone.blocks.2.0.bn1.bias\", \"backbone.blocks.2.0.bn1.running_mean\", \"backbone.blocks.2.0.bn1.running_var\", \"backbone.blocks.2.0.conv_dw.weight\", \"backbone.blocks.2.0.bn2.weight\", \"backbone.blocks.2.0.bn2.bias\", \"backbone.blocks.2.0.bn2.running_mean\", \"backbone.blocks.2.0.bn2.running_var\", \"backbone.blocks.2.0.se.conv_reduce.weight\", \"backbone.blocks.2.0.se.conv_reduce.bias\", \"backbone.blocks.2.0.se.conv_expand.weight\", \"backbone.blocks.2.0.se.conv_expand.bias\", \"backbone.blocks.2.0.conv_pwl.weight\", \"backbone.blocks.2.0.bn3.weight\", \"backbone.blocks.2.0.bn3.bias\", \"backbone.blocks.2.0.bn3.running_mean\", \"backbone.blocks.2.0.bn3.running_var\", \"backbone.blocks.2.1.conv_pw.weight\", \"backbone.blocks.2.1.bn1.weight\", \"backbone.blocks.2.1.bn1.bias\", \"backbone.blocks.2.1.bn1.running_mean\", \"backbone.blocks.2.1.bn1.running_var\", \"backbone.blocks.2.1.conv_dw.weight\", \"backbone.blocks.2.1.bn2.weight\", \"backbone.blocks.2.1.bn2.bias\", \"backbone.blocks.2.1.bn2.running_mean\", \"backbone.blocks.2.1.bn2.running_var\", \"backbone.blocks.2.1.se.conv_reduce.weight\", \"backbone.blocks.2.1.se.conv_reduce.bias\", \"backbone.blocks.2.1.se.conv_expand.weight\", \"backbone.blocks.2.1.se.conv_expand.bias\", \"backbone.blocks.2.1.conv_pwl.weight\", \"backbone.blocks.2.1.bn3.weight\", \"backbone.blocks.2.1.bn3.bias\", \"backbone.blocks.2.1.bn3.running_mean\", \"backbone.blocks.2.1.bn3.running_var\", \"backbone.blocks.3.0.conv_pw.weight\", \"backbone.blocks.3.0.bn1.weight\", \"backbone.blocks.3.0.bn1.bias\", \"backbone.blocks.3.0.bn1.running_mean\", \"backbone.blocks.3.0.bn1.running_var\", \"backbone.blocks.3.0.conv_dw.weight\", \"backbone.blocks.3.0.bn2.weight\", \"backbone.blocks.3.0.bn2.bias\", \"backbone.blocks.3.0.bn2.running_mean\", \"backbone.blocks.3.0.bn2.running_var\", \"backbone.blocks.3.0.se.conv_reduce.weight\", \"backbone.blocks.3.0.se.conv_reduce.bias\", \"backbone.blocks.3.0.se.conv_expand.weight\", \"backbone.blocks.3.0.se.conv_expand.bias\", \"backbone.blocks.3.0.conv_pwl.weight\", \"backbone.blocks.3.0.bn3.weight\", \"backbone.blocks.3.0.bn3.bias\", \"backbone.blocks.3.0.bn3.running_mean\", \"backbone.blocks.3.0.bn3.running_var\", \"backbone.blocks.3.1.conv_pw.weight\", \"backbone.blocks.3.1.bn1.weight\", \"backbone.blocks.3.1.bn1.bias\", \"backbone.blocks.3.1.bn1.running_mean\", \"backbone.blocks.3.1.bn1.running_var\", \"backbone.blocks.3.1.conv_dw.weight\", \"backbone.blocks.3.1.bn2.weight\", \"backbone.blocks.3.1.bn2.bias\", \"backbone.blocks.3.1.bn2.running_mean\", \"backbone.blocks.3.1.bn2.running_var\", \"backbone.blocks.3.1.se.conv_reduce.weight\", \"backbone.blocks.3.1.se.conv_reduce.bias\", \"backbone.blocks.3.1.se.conv_expand.weight\", \"backbone.blocks.3.1.se.conv_expand.bias\", \"backbone.blocks.3.1.conv_pwl.weight\", \"backbone.blocks.3.1.bn3.weight\", \"backbone.blocks.3.1.bn3.bias\", \"backbone.blocks.3.1.bn3.running_mean\", \"backbone.blocks.3.1.bn3.running_var\", \"backbone.blocks.3.2.conv_pw.weight\", \"backbone.blocks.3.2.bn1.weight\", \"backbone.blocks.3.2.bn1.bias\", \"backbone.blocks.3.2.bn1.running_mean\", \"backbone.blocks.3.2.bn1.running_var\", \"backbone.blocks.3.2.conv_dw.weight\", \"backbone.blocks.3.2.bn2.weight\", \"backbone.blocks.3.2.bn2.bias\", \"backbone.blocks.3.2.bn2.running_mean\", \"backbone.blocks.3.2.bn2.running_var\", \"backbone.blocks.3.2.se.conv_reduce.weight\", \"backbone.blocks.3.2.se.conv_reduce.bias\", \"backbone.blocks.3.2.se.conv_expand.weight\", \"backbone.blocks.3.2.se.conv_expand.bias\", \"backbone.blocks.3.2.conv_pwl.weight\", \"backbone.blocks.3.2.bn3.weight\", \"backbone.blocks.3.2.bn3.bias\", \"backbone.blocks.3.2.bn3.running_mean\", \"backbone.blocks.3.2.bn3.running_var\", \"backbone.blocks.4.0.conv_pw.weight\", \"backbone.blocks.4.0.bn1.weight\", \"backbone.blocks.4.0.bn1.bias\", \"backbone.blocks.4.0.bn1.running_mean\", \"backbone.blocks.4.0.bn1.running_var\", \"backbone.blocks.4.0.conv_dw.weight\", \"backbone.blocks.4.0.bn2.weight\", \"backbone.blocks.4.0.bn2.bias\", \"backbone.blocks.4.0.bn2.running_mean\", \"backbone.blocks.4.0.bn2.running_var\", \"backbone.blocks.4.0.se.conv_reduce.weight\", \"backbone.blocks.4.0.se.conv_reduce.bias\", \"backbone.blocks.4.0.se.conv_expand.weight\", \"backbone.blocks.4.0.se.conv_expand.bias\", \"backbone.blocks.4.0.conv_pwl.weight\", \"backbone.blocks.4.0.bn3.weight\", \"backbone.blocks.4.0.bn3.bias\", \"backbone.blocks.4.0.bn3.running_mean\", \"backbone.blocks.4.0.bn3.running_var\", \"backbone.blocks.4.1.conv_pw.weight\", \"backbone.blocks.4.1.bn1.weight\", \"backbone.blocks.4.1.bn1.bias\", \"backbone.blocks.4.1.bn1.running_mean\", \"backbone.blocks.4.1.bn1.running_var\", \"backbone.blocks.4.1.conv_dw.weight\", \"backbone.blocks.4.1.bn2.weight\", \"backbone.blocks.4.1.bn2.bias\", \"backbone.blocks.4.1.bn2.running_mean\", \"backbone.blocks.4.1.bn2.running_var\", \"backbone.blocks.4.1.se.conv_reduce.weight\", \"backbone.blocks.4.1.se.conv_reduce.bias\", \"backbone.blocks.4.1.se.conv_expand.weight\", \"backbone.blocks.4.1.se.conv_expand.bias\", \"backbone.blocks.4.1.conv_pwl.weight\", \"backbone.blocks.4.1.bn3.weight\", \"backbone.blocks.4.1.bn3.bias\", \"backbone.blocks.4.1.bn3.running_mean\", \"backbone.blocks.4.1.bn3.running_var\", \"backbone.blocks.4.2.conv_pw.weight\", \"backbone.blocks.4.2.bn1.weight\", \"backbone.blocks.4.2.bn1.bias\", \"backbone.blocks.4.2.bn1.running_mean\", \"backbone.blocks.4.2.bn1.running_var\", \"backbone.blocks.4.2.conv_dw.weight\", \"backbone.blocks.4.2.bn2.weight\", \"backbone.blocks.4.2.bn2.bias\", \"backbone.blocks.4.2.bn2.running_mean\", \"backbone.blocks.4.2.bn2.running_var\", \"backbone.blocks.4.2.se.conv_reduce.weight\", \"backbone.blocks.4.2.se.conv_reduce.bias\", \"backbone.blocks.4.2.se.conv_expand.weight\", \"backbone.blocks.4.2.se.conv_expand.bias\", \"backbone.blocks.4.2.conv_pwl.weight\", \"backbone.blocks.4.2.bn3.weight\", \"backbone.blocks.4.2.bn3.bias\", \"backbone.blocks.4.2.bn3.running_mean\", \"backbone.blocks.4.2.bn3.running_var\", \"backbone.blocks.5.0.conv_pw.weight\", \"backbone.blocks.5.0.bn1.weight\", \"backbone.blocks.5.0.bn1.bias\", \"backbone.blocks.5.0.bn1.running_mean\", \"backbone.blocks.5.0.bn1.running_var\", \"backbone.blocks.5.0.conv_dw.weight\", \"backbone.blocks.5.0.bn2.weight\", \"backbone.blocks.5.0.bn2.bias\", \"backbone.blocks.5.0.bn2.running_mean\", \"backbone.blocks.5.0.bn2.running_var\", \"backbone.blocks.5.0.se.conv_reduce.weight\", \"backbone.blocks.5.0.se.conv_reduce.bias\", \"backbone.blocks.5.0.se.conv_expand.weight\", \"backbone.blocks.5.0.se.conv_expand.bias\", \"backbone.blocks.5.0.conv_pwl.weight\", \"backbone.blocks.5.0.bn3.weight\", \"backbone.blocks.5.0.bn3.bias\", \"backbone.blocks.5.0.bn3.running_mean\", \"backbone.blocks.5.0.bn3.running_var\", \"backbone.blocks.5.1.conv_pw.weight\", \"backbone.blocks.5.1.bn1.weight\", \"backbone.blocks.5.1.bn1.bias\", \"backbone.blocks.5.1.bn1.running_mean\", \"backbone.blocks.5.1.bn1.running_var\", \"backbone.blocks.5.1.conv_dw.weight\", \"backbone.blocks.5.1.bn2.weight\", \"backbone.blocks.5.1.bn2.bias\", \"backbone.blocks.5.1.bn2.running_mean\", \"backbone.blocks.5.1.bn2.running_var\", \"backbone.blocks.5.1.se.conv_reduce.weight\", \"backbone.blocks.5.1.se.conv_reduce.bias\", \"backbone.blocks.5.1.se.conv_expand.weight\", \"backbone.blocks.5.1.se.conv_expand.bias\", \"backbone.blocks.5.1.conv_pwl.weight\", \"backbone.blocks.5.1.bn3.weight\", \"backbone.blocks.5.1.bn3.bias\", \"backbone.blocks.5.1.bn3.running_mean\", \"backbone.blocks.5.1.bn3.running_var\", \"backbone.blocks.5.2.conv_pw.weight\", \"backbone.blocks.5.2.bn1.weight\", \"backbone.blocks.5.2.bn1.bias\", \"backbone.blocks.5.2.bn1.running_mean\", \"backbone.blocks.5.2.bn1.running_var\", \"backbone.blocks.5.2.conv_dw.weight\", \"backbone.blocks.5.2.bn2.weight\", \"backbone.blocks.5.2.bn2.bias\", \"backbone.blocks.5.2.bn2.running_mean\", \"backbone.blocks.5.2.bn2.running_var\", \"backbone.blocks.5.2.se.conv_reduce.weight\", \"backbone.blocks.5.2.se.conv_reduce.bias\", \"backbone.blocks.5.2.se.conv_expand.weight\", \"backbone.blocks.5.2.se.conv_expand.bias\", \"backbone.blocks.5.2.conv_pwl.weight\", \"backbone.blocks.5.2.bn3.weight\", \"backbone.blocks.5.2.bn3.bias\", \"backbone.blocks.5.2.bn3.running_mean\", \"backbone.blocks.5.2.bn3.running_var\", \"backbone.blocks.5.3.conv_pw.weight\", \"backbone.blocks.5.3.bn1.weight\", \"backbone.blocks.5.3.bn1.bias\", \"backbone.blocks.5.3.bn1.running_mean\", \"backbone.blocks.5.3.bn1.running_var\", \"backbone.blocks.5.3.conv_dw.weight\", \"backbone.blocks.5.3.bn2.weight\", \"backbone.blocks.5.3.bn2.bias\", \"backbone.blocks.5.3.bn2.running_mean\", \"backbone.blocks.5.3.bn2.running_var\", \"backbone.blocks.5.3.se.conv_reduce.weight\", \"backbone.blocks.5.3.se.conv_reduce.bias\", \"backbone.blocks.5.3.se.conv_expand.weight\", \"backbone.blocks.5.3.se.conv_expand.bias\", \"backbone.blocks.5.3.conv_pwl.weight\", \"backbone.blocks.5.3.bn3.weight\", \"backbone.blocks.5.3.bn3.bias\", \"backbone.blocks.5.3.bn3.running_mean\", \"backbone.blocks.5.3.bn3.running_var\", \"backbone.blocks.6.0.conv_pw.weight\", \"backbone.blocks.6.0.bn1.weight\", \"backbone.blocks.6.0.bn1.bias\", \"backbone.blocks.6.0.bn1.running_mean\", \"backbone.blocks.6.0.bn1.running_var\", \"backbone.blocks.6.0.conv_dw.weight\", \"backbone.blocks.6.0.bn2.weight\", \"backbone.blocks.6.0.bn2.bias\", \"backbone.blocks.6.0.bn2.running_mean\", \"backbone.blocks.6.0.bn2.running_var\", \"backbone.blocks.6.0.se.conv_reduce.weight\", \"backbone.blocks.6.0.se.conv_reduce.bias\", \"backbone.blocks.6.0.se.conv_expand.weight\", \"backbone.blocks.6.0.se.conv_expand.bias\", \"backbone.blocks.6.0.conv_pwl.weight\", \"backbone.blocks.6.0.bn3.weight\", \"backbone.blocks.6.0.bn3.bias\", \"backbone.blocks.6.0.bn3.running_mean\", \"backbone.blocks.6.0.bn3.running_var\", \"backbone.conv_head.weight\", \"backbone.bn2.weight\", \"backbone.bn2.bias\", \"backbone.bn2.running_mean\", \"backbone.bn2.running_var\", \"classifier.weight\", \"classifier.bias\". \n\tUnexpected key(s) in state_dict: \"bn0.weight\", \"bn0.bias\", \"bn0.running_mean\", \"bn0.running_var\", \"bn0.num_batches_tracked\", \"encoder.0.0.weight\", \"encoder.0.1.weight\", \"encoder.0.1.bias\", \"encoder.0.1.running_mean\", \"encoder.0.1.running_var\", \"encoder.0.1.num_batches_tracked\", \"encoder.0.3.weight\", \"encoder.0.4.weight\", \"encoder.0.4.bias\", \"encoder.0.4.running_mean\", \"encoder.0.4.running_var\", \"encoder.0.4.num_batches_tracked\", \"encoder.0.6.weight\", \"encoder.1.weight\", \"encoder.1.bias\", \"encoder.1.running_mean\", \"encoder.1.running_var\", \"encoder.1.num_batches_tracked\", \"encoder.4.0.conv1.weight\", \"encoder.4.0.bn1.weight\", \"encoder.4.0.bn1.bias\", \"encoder.4.0.bn1.running_mean\", \"encoder.4.0.bn1.running_var\", \"encoder.4.0.bn1.num_batches_tracked\", \"encoder.4.0.conv2.weight\", \"encoder.4.0.bn2.weight\", \"encoder.4.0.bn2.bias\", \"encoder.4.0.bn2.running_mean\", \"encoder.4.0.bn2.running_var\", \"encoder.4.0.bn2.num_batches_tracked\", \"encoder.4.0.conv3.weight\", \"encoder.4.0.bn3.weight\", \"encoder.4.0.bn3.bias\", \"encoder.4.0.bn3.running_mean\", \"encoder.4.0.bn3.running_var\", \"encoder.4.0.bn3.num_batches_tracked\", \"encoder.4.0.se.fc1.weight\", \"encoder.4.0.se.fc1.bias\", \"encoder.4.0.se.fc2.weight\", \"encoder.4.0.se.fc2.bias\", \"encoder.4.0.downsample.1.weight\", \"encoder.4.0.downsample.2.weight\", \"encoder.4.0.downsample.2.bias\", \"encoder.4.0.downsample.2.running_mean\", \"encoder.4.0.downsample.2.running_var\", \"encoder.4.0.downsample.2.num_batches_tracked\", \"encoder.4.1.conv1.weight\", \"encoder.4.1.bn1.weight\", \"encoder.4.1.bn1.bias\", \"encoder.4.1.bn1.running_mean\", \"encoder.4.1.bn1.running_var\", \"encoder.4.1.bn1.num_batches_tracked\", \"encoder.4.1.conv2.weight\", \"encoder.4.1.bn2.weight\", \"encoder.4.1.bn2.bias\", \"encoder.4.1.bn2.running_mean\", \"encoder.4.1.bn2.running_var\", \"encoder.4.1.bn2.num_batches_tracked\", \"encoder.4.1.conv3.weight\", \"encoder.4.1.bn3.weight\", \"encoder.4.1.bn3.bias\", \"encoder.4.1.bn3.running_mean\", \"encoder.4.1.bn3.running_var\", \"encoder.4.1.bn3.num_batches_tracked\", \"encoder.4.1.se.fc1.weight\", \"encoder.4.1.se.fc1.bias\", \"encoder.4.1.se.fc2.weight\", \"encoder.4.1.se.fc2.bias\", \"encoder.5.0.conv1.weight\", \"encoder.5.0.bn1.weight\", \"encoder.5.0.bn1.bias\", \"encoder.5.0.bn1.running_mean\", \"encoder.5.0.bn1.running_var\", \"encoder.5.0.bn1.num_batches_tracked\", \"encoder.5.0.conv2.weight\", \"encoder.5.0.bn2.weight\", \"encoder.5.0.bn2.bias\", \"encoder.5.0.bn2.running_mean\", \"encoder.5.0.bn2.running_var\", \"encoder.5.0.bn2.num_batches_tracked\", \"encoder.5.0.conv3.weight\", \"encoder.5.0.bn3.weight\", \"encoder.5.0.bn3.bias\", \"encoder.5.0.bn3.running_mean\", \"encoder.5.0.bn3.running_var\", \"encoder.5.0.bn3.num_batches_tracked\", \"encoder.5.0.se.fc1.weight\", \"encoder.5.0.se.fc1.bias\", \"encoder.5.0.se.fc2.weight\", \"encoder.5.0.se.fc2.bias\", \"encoder.5.0.downsample.1.weight\", \"encoder.5.0.downsample.2.weight\", \"encoder.5.0.downsample.2.bias\", \"encoder.5.0.downsample.2.running_mean\", \"encoder.5.0.downsample.2.running_var\", \"encoder.5.0.downsample.2.num_batches_tracked\", \"encoder.5.1.conv1.weight\", \"encoder.5.1.bn1.weight\", \"encoder.5.1.bn1.bias\", \"encoder.5.1.bn1.running_mean\", \"encoder.5.1.bn1.running_var\", \"encoder.5.1.bn1.num_batches_tracked\", \"encoder.5.1.conv2.weight\", \"encoder.5.1.bn2.weight\", \"encoder.5.1.bn2.bias\", \"encoder.5.1.bn2.running_mean\", \"encoder.5.1.bn2.running_var\", \"encoder.5.1.bn2.num_batches_tracked\", \"encoder.5.1.conv3.weight\", \"encoder.5.1.bn3.weight\", \"encoder.5.1.bn3.bias\", \"encoder.5.1.bn3.running_mean\", \"encoder.5.1.bn3.running_var\", \"encoder.5.1.bn3.num_batches_tracked\", \"encoder.5.1.se.fc1.weight\", \"encoder.5.1.se.fc1.bias\", \"encoder.5.1.se.fc2.weight\", \"encoder.5.1.se.fc2.bias\", \"encoder.6.0.conv1.weight\", \"encoder.6.0.bn1.weight\", \"encoder.6.0.bn1.bias\", \"encoder.6.0.bn1.running_mean\", \"encoder.6.0.bn1.running_var\", \"encoder.6.0.bn1.num_batches_tracked\", \"encoder.6.0.conv2.weight\", \"encoder.6.0.bn2.weight\", \"encoder.6.0.bn2.bias\", \"encoder.6.0.bn2.running_mean\", \"encoder.6.0.bn2.running_var\", \"encoder.6.0.bn2.num_batches_tracked\", \"encoder.6.0.conv3.weight\", \"encoder.6.0.bn3.weight\", \"encoder.6.0.bn3.bias\", \"encoder.6.0.bn3.running_mean\", \"encoder.6.0.bn3.running_var\", \"encoder.6.0.bn3.num_batches_tracked\", \"encoder.6.0.se.fc1.weight\", \"encoder.6.0.se.fc1.bias\", \"encoder.6.0.se.fc2.weight\", \"encoder.6.0.se.fc2.bias\", \"encoder.6.0.downsample.1.weight\", \"encoder.6.0.downsample.2.weight\", \"encoder.6.0.downsample.2.bias\", \"encoder.6.0.downsample.2.running_mean\", \"encoder.6.0.downsample.2.running_var\", \"encoder.6.0.downsample.2.num_batches_tracked\", \"encoder.6.1.conv1.weight\", \"encoder.6.1.bn1.weight\", \"encoder.6.1.bn1.bias\", \"encoder.6.1.bn1.running_mean\", \"encoder.6.1.bn1.running_var\", \"encoder.6.1.bn1.num_batches_tracked\", \"encoder.6.1.conv2.weight\", \"encoder.6.1.bn2.weight\", \"encoder.6.1.bn2.bias\", \"encoder.6.1.bn2.running_mean\", \"encoder.6.1.bn2.running_var\", \"encoder.6.1.bn2.num_batches_tracked\", \"encoder.6.1.conv3.weight\", \"encoder.6.1.bn3.weight\", \"encoder.6.1.bn3.bias\", \"encoder.6.1.bn3.running_mean\", \"encoder.6.1.bn3.running_var\", \"encoder.6.1.bn3.num_batches_tracked\", \"encoder.6.1.se.fc1.weight\", \"encoder.6.1.se.fc1.bias\", \"encoder.6.1.se.fc2.weight\", \"encoder.6.1.se.fc2.bias\", \"encoder.7.0.conv1.weight\", \"encoder.7.0.bn1.weight\", \"encoder.7.0.bn1.bias\", \"encoder.7.0.bn1.running_mean\", \"encoder.7.0.bn1.running_var\", \"encoder.7.0.bn1.num_batches_tracked\", \"encoder.7.0.conv2.weight\", \"encoder.7.0.bn2.weight\", \"encoder.7.0.bn2.bias\", \"encoder.7.0.bn2.running_mean\", \"encoder.7.0.bn2.running_var\", \"encoder.7.0.bn2.num_batches_tracked\", \"encoder.7.0.conv3.weight\", \"encoder.7.0.bn3.weight\", \"encoder.7.0.bn3.bias\", \"encoder.7.0.bn3.running_mean\", \"encoder.7.0.bn3.running_var\", \"encoder.7.0.bn3.num_batches_tracked\", \"encoder.7.0.se.fc1.weight\", \"encoder.7.0.se.fc1.bias\", \"encoder.7.0.se.fc2.weight\", \"encoder.7.0.se.fc2.bias\", \"encoder.7.0.downsample.1.weight\", \"encoder.7.0.downsample.2.weight\", \"encoder.7.0.downsample.2.bias\", \"encoder.7.0.downsample.2.running_mean\", \"encoder.7.0.downsample.2.running_var\", \"encoder.7.0.downsample.2.num_batches_tracked\", \"encoder.7.1.conv1.weight\", \"encoder.7.1.bn1.weight\", \"encoder.7.1.bn1.bias\", \"encoder.7.1.bn1.running_mean\", \"encoder.7.1.bn1.running_var\", \"encoder.7.1.bn1.num_batches_tracked\", \"encoder.7.1.conv2.weight\", \"encoder.7.1.bn2.weight\", \"encoder.7.1.bn2.bias\", \"encoder.7.1.bn2.running_mean\", \"encoder.7.1.bn2.running_var\", \"encoder.7.1.bn2.num_batches_tracked\", \"encoder.7.1.conv3.weight\", \"encoder.7.1.bn3.weight\", \"encoder.7.1.bn3.bias\", \"encoder.7.1.bn3.running_mean\", \"encoder.7.1.bn3.running_var\", \"encoder.7.1.bn3.num_batches_tracked\", \"encoder.7.1.se.fc1.weight\", \"encoder.7.1.se.fc1.bias\", \"encoder.7.1.se.fc2.weight\", \"encoder.7.1.se.fc2.bias\", \"fc1.weight\", \"fc1.bias\", \"att_block.att.weight\", \"att_block.att.bias\", \"att_block.cla.weight\", \"att_block.cla.bias\", \"melspec_transform.spectrogram.window\", \"melspec_transform.mel_scale.fb\", \"backbone.conv1.0.weight\", \"backbone.conv1.1.weight\", \"backbone.conv1.1.bias\", \"backbone.conv1.1.running_mean\", \"backbone.conv1.1.running_var\", \"backbone.conv1.1.num_batches_tracked\", \"backbone.conv1.3.weight\", \"backbone.conv1.4.weight\", \"backbone.conv1.4.bias\", \"backbone.conv1.4.running_mean\", \"backbone.conv1.4.running_var\", \"backbone.conv1.4.num_batches_tracked\", \"backbone.conv1.6.weight\", \"backbone.layer1.0.conv1.weight\", \"backbone.layer1.0.bn1.weight\", \"backbone.layer1.0.bn1.bias\", \"backbone.layer1.0.bn1.running_mean\", \"backbone.layer1.0.bn1.running_var\", \"backbone.layer1.0.bn1.num_batches_tracked\", \"backbone.layer1.0.conv2.weight\", \"backbone.layer1.0.bn2.weight\", \"backbone.layer1.0.bn2.bias\", \"backbone.layer1.0.bn2.running_mean\", \"backbone.layer1.0.bn2.running_var\", \"backbone.layer1.0.bn2.num_batches_tracked\", \"backbone.layer1.0.conv3.weight\", \"backbone.layer1.0.bn3.weight\", \"backbone.layer1.0.bn3.bias\", \"backbone.layer1.0.bn3.running_mean\", \"backbone.layer1.0.bn3.running_var\", \"backbone.layer1.0.bn3.num_batches_tracked\", \"backbone.layer1.0.se.fc1.weight\", \"backbone.layer1.0.se.fc1.bias\", \"backbone.layer1.0.se.fc2.weight\", \"backbone.layer1.0.se.fc2.bias\", \"backbone.layer1.0.downsample.1.weight\", \"backbone.layer1.0.downsample.2.weight\", \"backbone.layer1.0.downsample.2.bias\", \"backbone.layer1.0.downsample.2.running_mean\", \"backbone.layer1.0.downsample.2.running_var\", \"backbone.layer1.0.downsample.2.num_batches_tracked\", \"backbone.layer1.1.conv1.weight\", \"backbone.layer1.1.bn1.weight\", \"backbone.layer1.1.bn1.bias\", \"backbone.layer1.1.bn1.running_mean\", \"backbone.layer1.1.bn1.running_var\", \"backbone.layer1.1.bn1.num_batches_tracked\", \"backbone.layer1.1.conv2.weight\", \"backbone.layer1.1.bn2.weight\", \"backbone.layer1.1.bn2.bias\", \"backbone.layer1.1.bn2.running_mean\", \"backbone.layer1.1.bn2.running_var\", \"backbone.layer1.1.bn2.num_batches_tracked\", \"backbone.layer1.1.conv3.weight\", \"backbone.layer1.1.bn3.weight\", \"backbone.layer1.1.bn3.bias\", \"backbone.layer1.1.bn3.running_mean\", \"backbone.layer1.1.bn3.running_var\", \"backbone.layer1.1.bn3.num_batches_tracked\", \"backbone.layer1.1.se.fc1.weight\", \"backbone.layer1.1.se.fc1.bias\", \"backbone.layer1.1.se.fc2.weight\", \"backbone.layer1.1.se.fc2.bias\", \"backbone.layer2.0.conv1.weight\", \"backbone.layer2.0.bn1.weight\", \"backbone.layer2.0.bn1.bias\", \"backbone.layer2.0.bn1.running_mean\", \"backbone.layer2.0.bn1.running_var\", \"backbone.layer2.0.bn1.num_batches_tracked\", \"backbone.layer2.0.conv2.weight\", \"backbone.layer2.0.bn2.weight\", \"backbone.layer2.0.bn2.bias\", \"backbone.layer2.0.bn2.running_mean\", \"backbone.layer2.0.bn2.running_var\", \"backbone.layer2.0.bn2.num_batches_tracked\", \"backbone.layer2.0.conv3.weight\", \"backbone.layer2.0.bn3.weight\", \"backbone.layer2.0.bn3.bias\", \"backbone.layer2.0.bn3.running_mean\", \"backbone.layer2.0.bn3.running_var\", \"backbone.layer2.0.bn3.num_batches_tracked\", \"backbone.layer2.0.se.fc1.weight\", \"backbone.layer2.0.se.fc1.bias\", \"backbone.layer2.0.se.fc2.weight\", \"backbone.layer2.0.se.fc2.bias\", \"backbone.layer2.0.downsample.1.weight\", \"backbone.layer2.0.downsample.2.weight\", \"backbone.layer2.0.downsample.2.bias\", \"backbone.layer2.0.downsample.2.running_mean\", \"backbone.layer2.0.downsample.2.running_var\", \"backbone.layer2.0.downsample.2.num_batches_tracked\", \"backbone.layer2.1.conv1.weight\", \"backbone.layer2.1.bn1.weight\", \"backbone.layer2.1.bn1.bias\", \"backbone.layer2.1.bn1.running_mean\", \"backbone.layer2.1.bn1.running_var\", \"backbone.layer2.1.bn1.num_batches_tracked\", \"backbone.layer2.1.conv2.weight\", \"backbone.layer2.1.bn2.weight\", \"backbone.layer2.1.bn2.bias\", \"backbone.layer2.1.bn2.running_mean\", \"backbone.layer2.1.bn2.running_var\", \"backbone.layer2.1.bn2.num_batches_tracked\", \"backbone.layer2.1.conv3.weight\", \"backbone.layer2.1.bn3.weight\", \"backbone.layer2.1.bn3.bias\", \"backbone.layer2.1.bn3.running_mean\", \"backbone.layer2.1.bn3.running_var\", \"backbone.layer2.1.bn3.num_batches_tracked\", \"backbone.layer2.1.se.fc1.weight\", \"backbone.layer2.1.se.fc1.bias\", \"backbone.layer2.1.se.fc2.weight\", \"backbone.layer2.1.se.fc2.bias\", \"backbone.layer3.0.conv1.weight\", \"backbone.layer3.0.bn1.weight\", \"backbone.layer3.0.bn1.bias\", \"backbone.layer3.0.bn1.running_mean\", \"backbone.layer3.0.bn1.running_var\", \"backbone.layer3.0.bn1.num_batches_tracked\", \"backbone.layer3.0.conv2.weight\", \"backbone.layer3.0.bn2.weight\", \"backbone.layer3.0.bn2.bias\", \"backbone.layer3.0.bn2.running_mean\", \"backbone.layer3.0.bn2.running_var\", \"backbone.layer3.0.bn2.num_batches_tracked\", \"backbone.layer3.0.conv3.weight\", \"backbone.layer3.0.bn3.weight\", \"backbone.layer3.0.bn3.bias\", \"backbone.layer3.0.bn3.running_mean\", \"backbone.layer3.0.bn3.running_var\", \"backbone.layer3.0.bn3.num_batches_tracked\", \"backbone.layer3.0.se.fc1.weight\", \"backbone.layer3.0.se.fc1.bias\", \"backbone.layer3.0.se.fc2.weight\", \"backbone.layer3.0.se.fc2.bias\", \"backbone.layer3.0.downsample.1.weight\", \"backbone.layer3.0.downsample.2.weight\", \"backbone.layer3.0.downsample.2.bias\", \"backbone.layer3.0.downsample.2.running_mean\", \"backbone.layer3.0.downsample.2.running_var\", \"backbone.layer3.0.downsample.2.num_batches_tracked\", \"backbone.layer3.1.conv1.weight\", \"backbone.layer3.1.bn1.weight\", \"backbone.layer3.1.bn1.bias\", \"backbone.layer3.1.bn1.running_mean\", \"backbone.layer3.1.bn1.running_var\", \"backbone.layer3.1.bn1.num_batches_tracked\", \"backbone.layer3.1.conv2.weight\", \"backbone.layer3.1.bn2.weight\", \"backbone.layer3.1.bn2.bias\", \"backbone.layer3.1.bn2.running_mean\", \"backbone.layer3.1.bn2.running_var\", \"backbone.layer3.1.bn2.num_batches_tracked\", \"backbone.layer3.1.conv3.weight\", \"backbone.layer3.1.bn3.weight\", \"backbone.layer3.1.bn3.bias\", \"backbone.layer3.1.bn3.running_mean\", \"backbone.layer3.1.bn3.running_var\", \"backbone.layer3.1.bn3.num_batches_tracked\", \"backbone.layer3.1.se.fc1.weight\", \"backbone.layer3.1.se.fc1.bias\", \"backbone.layer3.1.se.fc2.weight\", \"backbone.layer3.1.se.fc2.bias\", \"backbone.layer4.0.conv1.weight\", \"backbone.layer4.0.bn1.weight\", \"backbone.layer4.0.bn1.bias\", \"backbone.layer4.0.bn1.running_mean\", \"backbone.layer4.0.bn1.running_var\", \"backbone.layer4.0.bn1.num_batches_tracked\", \"backbone.layer4.0.conv2.weight\", \"backbone.layer4.0.bn2.weight\", \"backbone.layer4.0.bn2.bias\", \"backbone.layer4.0.bn2.running_mean\", \"backbone.layer4.0.bn2.running_var\", \"backbone.layer4.0.bn2.num_batches_tracked\", \"backbone.layer4.0.conv3.weight\", \"backbone.layer4.0.bn3.weight\", \"backbone.layer4.0.bn3.bias\", \"backbone.layer4.0.bn3.running_mean\", \"backbone.layer4.0.bn3.running_var\", \"backbone.layer4.0.bn3.num_batches_tracked\", \"backbone.layer4.0.se.fc1.weight\", \"backbone.layer4.0.se.fc1.bias\", \"backbone.layer4.0.se.fc2.weight\", \"backbone.layer4.0.se.fc2.bias\", \"backbone.layer4.0.downsample.1.weight\", \"backbone.layer4.0.downsample.2.weight\", \"backbone.layer4.0.downsample.2.bias\", \"backbone.layer4.0.downsample.2.running_mean\", \"backbone.layer4.0.downsample.2.running_var\", \"backbone.layer4.0.downsample.2.num_batches_tracked\", \"backbone.layer4.1.conv1.weight\", \"backbone.layer4.1.bn1.weight\", \"backbone.layer4.1.bn1.bias\", \"backbone.layer4.1.bn1.running_mean\", \"backbone.layer4.1.bn1.running_var\", \"backbone.layer4.1.bn1.num_batches_tracked\", \"backbone.layer4.1.conv2.weight\", \"backbone.layer4.1.bn2.weight\", \"backbone.layer4.1.bn2.bias\", \"backbone.layer4.1.bn2.running_mean\", \"backbone.layer4.1.bn2.running_var\", \"backbone.layer4.1.bn2.num_batches_tracked\", \"backbone.layer4.1.conv3.weight\", \"backbone.layer4.1.bn3.weight\", \"backbone.layer4.1.bn3.bias\", \"backbone.layer4.1.bn3.running_mean\", \"backbone.layer4.1.bn3.running_var\", \"backbone.layer4.1.bn3.num_batches_tracked\", \"backbone.layer4.1.se.fc1.weight\", \"backbone.layer4.1.se.fc1.bias\", \"backbone.layer4.1.se.fc2.weight\", \"backbone.layer4.1.se.fc2.bias\", \"backbone.fc.weight\", \"backbone.fc.bias\". \n\tsize mismatch for backbone.bn1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for backbone.bn1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for backbone.bn1.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for backbone.bn1.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n","output_type":"stream"}],"execution_count":2}]}